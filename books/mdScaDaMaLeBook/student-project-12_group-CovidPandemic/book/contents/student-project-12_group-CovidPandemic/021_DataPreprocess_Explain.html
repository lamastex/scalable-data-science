<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>021_DataPreprocess_Explain - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">00_ProjectDescriptionAndPlanning</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">01_DownloadFilesPeriodicallyScript</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/01_StreamToFile.html">01_StreamToFile</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/02_DataPreprocess.html">02_DataPreprocess</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html" class="active">021_DataPreprocess_Explain</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">03_ExplosiveAnalysis</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/04_DataVisualize.html">04_DataVisualize</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/05_Clustering.html">05_Clustering</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">06_DataPredicton_LR</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">07_DataPredicton_ARIMA</a></li><li class="chapter-item expanded affix "><a href="../../contents/student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">08_DataPrediction_GP</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="loading-data"><a class="header" href="#loading-data">Loading data</a></h2>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(dbutils.fs.ls(&quot;/datasets/group12/&quot;))
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>path</th>
<th>name</th>
<th>size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>dbfs:/datasets/group12/20_12_04_08_31_44.csv</td>
<td>20_12_04_08_31_44.csv</td>
<td>1.4181338e7</td>
</tr>
<tr class="even">
<td>dbfs:/datasets/group12/20_12_04_08_32_40.csv</td>
<td>20_12_04_08_32_40.csv</td>
<td>1.4181338e7</td>
</tr>
<tr class="odd">
<td>dbfs:/datasets/group12/20_12_04_10_47_08.csv</td>
<td>20_12_04_10_47_08.csv</td>
<td>1.4190774e7</td>
</tr>
<tr class="even">
<td>dbfs:/datasets/group12/21_01_07_08_50_05.csv</td>
<td>21_01_07_08_50_05.csv</td>
<td>1.4577033e7</td>
</tr>
<tr class="odd">
<td>dbfs:/datasets/group12/21_01_07_09_05_33.csv</td>
<td>21_01_07_09_05_33.csv</td>
<td>1.4577033e7</td>
</tr>
<tr class="even">
<td>dbfs:/datasets/group12/analysis/</td>
<td>analysis/</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td>dbfs:/datasets/group12/chkpoint/</td>
<td>chkpoint/</td>
<td>0.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>Load parquet file</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df = spark.read.parquet(&quot;dbfs:/datasets/group12/analysis/*.parquet&quot;)

display(df)
</code></pre>
</div>
<div class="cell markdown">
<p>Load csv file</p>
</div>
<div class="cell markdown">
<p>-&gt; %scala //if want to load csv</p>
<p>val file<em>location = &quot;/datasets/group12/20</em>12<em>04</em>10<em>47</em>08.csv&quot; val file_type = &quot;csv&quot;</p>
<p>// CSV options val infer<em>schema = &quot;true&quot; val first</em>row<em>is</em>header = &quot;true&quot; val delimiter = &quot;,&quot;</p>
<p>// The applied options are for CSV files. For other file types, these will be ignored. val df = spark.read.format(file<em>type) .option(&quot;inferSchema&quot;, infer</em>schema) .option(&quot;header&quot;, first<em>row</em>is<em>header) .option(&quot;sep&quot;, delimiter) .load(file</em>location)</p>
<p>display(df)</p>
</div>
<div class="cell markdown">
<p>Number of data</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res19: Long = 60544
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Missing Features in data due to multiple web resource</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df.columns) {
  println(c + &quot;: &quot; + df.filter(col(c).isNull).count())
}
</code></pre>
</div>
<div class="cell markdown">
<h2 id="preprocessing"><a class="header" href="#preprocessing">Preprocessing</a></h2>
<h3 id="0-filter-out-data-of-hongkong-and-unknown-location"><a class="header" href="#0-filter-out-data-of-hongkong-and-unknown-location">0. filter out data of HongKong and unknown location</a></h3>
</div>
<div class="cell markdown">
<p>Here shows HK does not have meaningful value and there is one unknown international location in data.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df.filter($&quot;location&quot;===&quot;Hong Kong&quot; || $&quot;iso_code&quot;.isNull)) //HK data iteself is not complete for all dates, and all available data is null! HAVE TO FILTER IT OUT COMPLETELY
</code></pre>
</div>
<div class="cell markdown">
<p>190 valid countries data to continue</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_filteredLocation = df.filter($&quot;iso_code&quot;=!=&quot;HKG&quot;).filter($&quot;iso_code&quot;.isNotNull)
display(df_filteredLocation.select($&quot;location&quot;).distinct()) // 190 valid countries 
</code></pre>
</div>
<div class="cell markdown">
<p>Fill missing continent value for World aggregate data NOTE: it will be filled as &quot;World&quot;</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_filteredLocation.where($&quot;continent&quot;.isNull))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_fillContinentNull = df_filteredLocation.na.fill(&quot;World&quot;,Array(&quot;continent&quot;))
display(df_fillContinentNull)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df_fillContinentNull.count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res27: Long = 60158
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df_fillContinentNull.columns) {
  println(c + &quot;: &quot; + df_fillContinentNull.filter(col(c).isNull).count())
}
</code></pre>
</div>
<div class="cell markdown">
<h3 id="1-filter-dates-only-from-2020-01-23-to-ensure-all-countries-having-316-days-logging"><a class="header" href="#1-filter-dates-only-from-2020-01-23-to-ensure-all-countries-having-316-days-logging">1. filter dates only from 2020-01-23 (to ensure all countries having 316 days logging)</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_fillContinentNull.select($&quot;date&quot;,$&quot;iso_code&quot;).groupBy($&quot;iso_code&quot;).count())  // some country starts logging data earlier
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_filtered_date = df_fillContinentNull.filter($&quot;date&quot;&gt;&quot;2020-01-22&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df_filtered_date: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [iso_code: string, continent: string ... 48 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_filtered_date.select($&quot;date&quot;,$&quot;iso_code&quot;).groupBy($&quot;iso_code&quot;).count())  // all countries have 316 days logging
</code></pre>
</div>
<div class="cell markdown">
<h3 id="2-fill-missing-value-for-totalcases-totaldeaths-newcasessmoothed-newdeathssmoothed"><a class="header" href="#2-fill-missing-value-for-totalcases-totaldeaths-newcasessmoothed-newdeathssmoothed">2. Fill missing value for total<em>cases, total</em>deaths, new<em>cases</em>smoothed, new<em>deaths</em>smoothed</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_filtered_date.select($&quot;date&quot;,$&quot;iso_code&quot;, $&quot;total_cases&quot;, $&quot;total_deaths&quot;, $&quot;new_cases&quot;, $&quot;new_deaths&quot;, $&quot;new_cases_smoothed&quot;, $&quot;new_deaths_smoothed&quot;).filter($&quot;new_cases_smoothed&quot;.isNull || $&quot;new_deaths_smoothed&quot;.isNull))
</code></pre>
</div>
<div class="cell markdown">
<p>All missing data of new<em>cases</em>smoothed and new<em>deaths</em>smoothed from early, so just fill with 0</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_filtered_date.select($&quot;date&quot;,$&quot;iso_code&quot;, $&quot;total_cases&quot;, $&quot;total_deaths&quot;, $&quot;new_cases&quot;, $&quot;new_deaths&quot;, $&quot;new_cases_smoothed&quot;, $&quot;new_deaths_smoothed&quot;)
        .filter($&quot;new_cases_smoothed&quot;.isNull || $&quot;new_deaths_smoothed&quot;.isNull).select($&quot;date&quot;).distinct())
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2020-01-23</td>
</tr>
<tr class="even">
<td>2020-01-27</td>
</tr>
<tr class="odd">
<td>2020-01-24</td>
</tr>
<tr class="even">
<td>2020-01-26</td>
</tr>
<tr class="odd">
<td>2020-01-25</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_fillNullForSmooth = df_filtered_date.na.fill(0,Array(&quot;new_cases_smoothed&quot;))
                           .na.fill(0,Array(&quot;new_deaths_smoothed&quot;))
display(df_fillNullForSmooth)
</code></pre>
</div>
<div class="cell markdown">
<p>Fill total<em>deaths and total</em>cases null value</p>
<p>Strictly, when new<em>cases is always 0, total</em>cases could be imputed as 0. The same apply to total_deaths</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_NULL_total_cases = df_fillNullForSmooth.select($&quot;date&quot;,$&quot;iso_code&quot;, $&quot;total_cases&quot;, $&quot;total_deaths&quot;, $&quot;new_cases&quot;, $&quot;new_deaths&quot;, $&quot;new_cases_smoothed&quot;, $&quot;new_deaths_smoothed&quot;)
                          .filter($&quot;total_cases&quot;.isNull)


display(df_NULL_total_cases.filter($&quot;new_cases&quot;===0).groupBy(&quot;iso_code&quot;).count())
</code></pre>
</div>
<div class="cell markdown">
<p>When total<em>case is Null, all previous new</em>cases is always 0.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">df_NULL_total_cases.filter($&quot;total_cases&quot;.isNull).groupBy(&quot;iso_code&quot;).count().except(df_NULL_total_cases.filter($&quot;new_cases&quot;===0).groupBy(&quot;iso_code&quot;).count()).show() // When total_case is Null, all new_cases is always 0
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+-----+
|iso_code|count|
+--------+-----+
+--------+-----+
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_fillNullForTotalCases = df_fillNullForSmooth.na.fill(0, Array(&quot;total_cases&quot;))
                               
display(df_fillNullForTotalCases)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_NULL_total_death = df_fillNullForTotalCases.select($&quot;date&quot;,$&quot;iso_code&quot;, $&quot;total_cases&quot;, $&quot;total_deaths&quot;, $&quot;new_cases&quot;, $&quot;new_deaths&quot;, $&quot;new_cases_smoothed&quot;, $&quot;new_deaths_smoothed&quot;)
                          .filter($&quot;total_deaths&quot;.isNull)


display(df_NULL_total_death.filter($&quot;new_deaths&quot;===0).groupBy(&quot;iso_code&quot;).count().sort())
</code></pre>
</div>
<div class="cell markdown">
<p>If total<em>deaths is Null when all new</em>deaths is always 0, then we could simply assign 0 for NULL, otherwise need to investigate more.</p>
<p>Three countries (ISL, PNG, SVK) have abnormal correction on new_cases data.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val abnormal_countries = df_NULL_total_death.filter($&quot;total_deaths&quot;.isNull).groupBy(&quot;iso_code&quot;).count().except(df_NULL_total_death.filter($&quot;new_deaths&quot;===0).groupBy(&quot;iso_code&quot;).count())
abnormal_countries.show()
df_NULL_total_death.filter($&quot;new_deaths&quot;===0).groupBy(&quot;iso_code&quot;).count().except(df_NULL_total_death.filter($&quot;total_deaths&quot;.isNull).groupBy(&quot;iso_code&quot;).count()).show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+-----+
|iso_code|count|
+--------+-----+
|     PNG|  186|
|     SVK|   65|
|     ISL|   54|
+--------+-----+

+--------+-----+
|iso_code|count|
+--------+-----+
|     PNG|  185|
|     SVK|   64|
|     ISL|   52|
+--------+-----+

abnormal_countries: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [iso_code: string, count: bigint]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>show abnormal death correction</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_fillNullForSmooth.filter($&quot;iso_code&quot;===&quot;ISL&quot;).sort(&quot;date&quot;).filter($&quot;date&quot;&gt;&quot;2020-03-13&quot; &amp;&amp; $&quot;date&quot;&lt;&quot;2020-03-22&quot;)) // death data correction between 2020-03-14 and 2020-03-21, total_deaths -&gt; all 0, new_deaths -&gt; all 0, new_deaths_smoothed -&gt; all 0
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>iso_code</th>
<th>continent</th>
<th>location</th>
<th>date</th>
<th>total_cases</th>
<th>new_cases</th>
<th>new_cases_smoothed</th>
<th>total_deaths</th>
<th>new_deaths</th>
<th>new_deaths_smoothed</th>
<th>total_cases_per_million</th>
<th>new_cases_per_million</th>
<th>new_cases_smoothed_per_million</th>
<th>total_deaths_per_million</th>
<th>new_deaths_per_million</th>
<th>new_deaths_smoothed_per_million</th>
<th>reproduction_rate</th>
<th>icu_patients</th>
<th>icu_patients_per_million</th>
<th>hosp_patients</th>
<th>hosp_patients_per_million</th>
<th>weekly_icu_admissions</th>
<th>weekly_icu_admissions_per_million</th>
<th>weekly_hosp_admissions</th>
<th>weekly_hosp_admissions_per_million</th>
<th>total_tests</th>
<th>new_tests</th>
<th>total_tests_per_thousand</th>
<th>new_tests_per_thousand</th>
<th>new_tests_smoothed</th>
<th>new_tests_smoothed_per_thousand</th>
<th>tests_per_case</th>
<th>positive_rate</th>
<th>tests_units</th>
<th>stringency_index</th>
<th>population</th>
<th>population_density</th>
<th>median_age</th>
<th>aged_65_older</th>
<th>aged_70_older</th>
<th>gdp_per_capita</th>
<th>extreme_poverty</th>
<th>cardiovasc_death_rate</th>
<th>diabetes_prevalence</th>
<th>female_smokers</th>
<th>male_smokers</th>
<th>handwashing_facilities</th>
<th>hospital_beds_per_thousand</th>
<th>life_expectancy</th>
<th>human_development_index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-14</td>
<td>156.0</td>
<td>22.0</td>
<td>15.143</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>457.143</td>
<td>64.469</td>
<td>44.375</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>1.62</td>
<td>1.0</td>
<td>2.93</td>
<td>3.0</td>
<td>8.791</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>1827.0</td>
<td>323.0</td>
<td>5.354</td>
<td>0.947</td>
<td>198.0</td>
<td>0.58</td>
<td>7.6e-2</td>
<td>13.1</td>
<td>null</td>
<td>16.67</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="even">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-15</td>
<td>171.0</td>
<td>15.0</td>
<td>17.286</td>
<td>5.0</td>
<td>5.0</td>
<td>0.714</td>
<td>501.099</td>
<td>43.956</td>
<td>50.654</td>
<td>14.652</td>
<td>14.652</td>
<td>2.093</td>
<td>1.61</td>
<td>2.0</td>
<td>5.861</td>
<td>3.0</td>
<td>8.791</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>2902.0</td>
<td>1075.0</td>
<td>8.504</td>
<td>3.15</td>
<td>346.0</td>
<td>1.014</td>
<td>5.0e-2</td>
<td>20.0</td>
<td>null</td>
<td>25.0</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="odd">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-16</td>
<td>180.0</td>
<td>9.0</td>
<td>17.429</td>
<td>null</td>
<td>-5.0</td>
<td>0.0</td>
<td>527.473</td>
<td>26.374</td>
<td>51.073</td>
<td>null</td>
<td>-14.652</td>
<td>0.0</td>
<td>1.63</td>
<td>2.0</td>
<td>5.861</td>
<td>4.0</td>
<td>11.722</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>4609.0</td>
<td>1707.0</td>
<td>13.506</td>
<td>5.002</td>
<td>576.0</td>
<td>1.688</td>
<td>3.0e-2</td>
<td>33.0</td>
<td>null</td>
<td>50.93</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="even">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-17</td>
<td>220.0</td>
<td>40.0</td>
<td>21.571</td>
<td>1.0</td>
<td>1.0</td>
<td>0.143</td>
<td>644.689</td>
<td>117.216</td>
<td>63.213</td>
<td>2.93</td>
<td>2.93</td>
<td>0.419</td>
<td>1.7</td>
<td>2.0</td>
<td>5.861</td>
<td>5.0</td>
<td>14.652</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>6009.0</td>
<td>1400.0</td>
<td>17.609</td>
<td>4.103</td>
<td>752.0</td>
<td>2.204</td>
<td>2.9e-2</td>
<td>34.9</td>
<td>null</td>
<td>50.93</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="odd">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-18</td>
<td>250.0</td>
<td>30.0</td>
<td>23.571</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>732.601</td>
<td>87.912</td>
<td>69.074</td>
<td>2.93</td>
<td>0.0</td>
<td>0.419</td>
<td>1.73</td>
<td>0.0</td>
<td>0.0</td>
<td>6.0</td>
<td>17.582</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>7837.0</td>
<td>1828.0</td>
<td>22.966</td>
<td>5.357</td>
<td>992.0</td>
<td>2.907</td>
<td>2.4e-2</td>
<td>42.1</td>
<td>null</td>
<td>50.93</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="even">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-19</td>
<td>330.0</td>
<td>80.0</td>
<td>32.429</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>967.033</td>
<td>234.432</td>
<td>95.029</td>
<td>2.93</td>
<td>0.0</td>
<td>0.419</td>
<td>1.78</td>
<td>1.0</td>
<td>2.93</td>
<td>6.0</td>
<td>17.582</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>9148.0</td>
<td>1311.0</td>
<td>26.807</td>
<td>3.842</td>
<td>1143.0</td>
<td>3.349</td>
<td>2.8e-2</td>
<td>35.2</td>
<td>null</td>
<td>50.93</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="odd">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-20</td>
<td>409.0</td>
<td>79.0</td>
<td>39.286</td>
<td>null</td>
<td>-1.0</td>
<td>0.0</td>
<td>1198.535</td>
<td>231.502</td>
<td>115.123</td>
<td>null</td>
<td>-2.93</td>
<td>0.0</td>
<td>1.75</td>
<td>1.0</td>
<td>2.93</td>
<td>10.0</td>
<td>29.304</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>9727.0</td>
<td>579.0</td>
<td>28.504</td>
<td>1.697</td>
<td>1175.0</td>
<td>3.443</td>
<td>3.3e-2</td>
<td>29.9</td>
<td>null</td>
<td>53.7</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
<tr class="even">
<td>ISL</td>
<td>Europe</td>
<td>Iceland</td>
<td>2020-03-21</td>
<td>473.0</td>
<td>64.0</td>
<td>45.286</td>
<td>1.0</td>
<td>1.0</td>
<td>0.143</td>
<td>1386.081</td>
<td>187.546</td>
<td>132.705</td>
<td>2.93</td>
<td>2.93</td>
<td>0.419</td>
<td>1.68</td>
<td>1.0</td>
<td>2.93</td>
<td>12.0</td>
<td>35.165</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>10077.0</td>
<td>350.0</td>
<td>29.53</td>
<td>1.026</td>
<td>1179.0</td>
<td>3.455</td>
<td>3.8e-2</td>
<td>26.0</td>
<td>null</td>
<td>53.7</td>
<td>341250.0</td>
<td>3.404</td>
<td>37.3</td>
<td>14.431</td>
<td>9.207</td>
<td>46482.958</td>
<td>0.2</td>
<td>117.992</td>
<td>5.31</td>
<td>14.3</td>
<td>15.2</td>
<td>null</td>
<td>2.91</td>
<td>82.99</td>
<td>0.935</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_fillNullForSmooth.filter($&quot;iso_code&quot;===&quot;PNG&quot;).sort(&quot;date&quot;).filter($&quot;date&quot;&gt;&quot;2020-07-19&quot; &amp;&amp; $&quot;date&quot;&lt;&quot;2020-07-24&quot; )) // death data correction between 2020-07-20 and 2020-07-22, total_deaths -&gt; all 0, new_deaths -&gt; all 0, new_deaths_smoothed -&gt; all 0
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>iso_code</th>
<th>continent</th>
<th>location</th>
<th>date</th>
<th>total_cases</th>
<th>new_cases</th>
<th>new_cases_smoothed</th>
<th>total_deaths</th>
<th>new_deaths</th>
<th>new_deaths_smoothed</th>
<th>total_cases_per_million</th>
<th>new_cases_per_million</th>
<th>new_cases_smoothed_per_million</th>
<th>total_deaths_per_million</th>
<th>new_deaths_per_million</th>
<th>new_deaths_smoothed_per_million</th>
<th>reproduction_rate</th>
<th>icu_patients</th>
<th>icu_patients_per_million</th>
<th>hosp_patients</th>
<th>hosp_patients_per_million</th>
<th>weekly_icu_admissions</th>
<th>weekly_icu_admissions_per_million</th>
<th>weekly_hosp_admissions</th>
<th>weekly_hosp_admissions_per_million</th>
<th>total_tests</th>
<th>new_tests</th>
<th>total_tests_per_thousand</th>
<th>new_tests_per_thousand</th>
<th>new_tests_smoothed</th>
<th>new_tests_smoothed_per_thousand</th>
<th>tests_per_case</th>
<th>positive_rate</th>
<th>tests_units</th>
<th>stringency_index</th>
<th>population</th>
<th>population_density</th>
<th>median_age</th>
<th>aged_65_older</th>
<th>aged_70_older</th>
<th>gdp_per_capita</th>
<th>extreme_poverty</th>
<th>cardiovasc_death_rate</th>
<th>diabetes_prevalence</th>
<th>female_smokers</th>
<th>male_smokers</th>
<th>handwashing_facilities</th>
<th>hospital_beds_per_thousand</th>
<th>life_expectancy</th>
<th>human_development_index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PNG</td>
<td>Oceania</td>
<td>Papua New Guinea</td>
<td>2020-07-20</td>
<td>19.0</td>
<td>3.0</td>
<td>1.143</td>
<td>1.0</td>
<td>1.0</td>
<td>0.143</td>
<td>2.124</td>
<td>0.335</td>
<td>0.128</td>
<td>0.112</td>
<td>0.112</td>
<td>1.6e-2</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>45.37</td>
<td>8947027.0</td>
<td>18.22</td>
<td>22.6</td>
<td>3.808</td>
<td>2.142</td>
<td>3823.194</td>
<td>null</td>
<td>561.494</td>
<td>17.65</td>
<td>23.5</td>
<td>48.8</td>
<td>null</td>
<td>null</td>
<td>64.5</td>
<td>0.544</td>
</tr>
<tr class="even">
<td>PNG</td>
<td>Oceania</td>
<td>Papua New Guinea</td>
<td>2020-07-21</td>
<td>27.0</td>
<td>8.0</td>
<td>2.286</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>3.018</td>
<td>0.894</td>
<td>0.255</td>
<td>0.112</td>
<td>0.0</td>
<td>1.6e-2</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>45.37</td>
<td>8947027.0</td>
<td>18.22</td>
<td>22.6</td>
<td>3.808</td>
<td>2.142</td>
<td>3823.194</td>
<td>null</td>
<td>561.494</td>
<td>17.65</td>
<td>23.5</td>
<td>48.8</td>
<td>null</td>
<td>null</td>
<td>64.5</td>
<td>0.544</td>
</tr>
<tr class="odd">
<td>PNG</td>
<td>Oceania</td>
<td>Papua New Guinea</td>
<td>2020-07-22</td>
<td>30.0</td>
<td>3.0</td>
<td>2.714</td>
<td>null</td>
<td>-1.0</td>
<td>0.0</td>
<td>3.353</td>
<td>0.335</td>
<td>0.303</td>
<td>null</td>
<td>-0.112</td>
<td>0.0</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>45.37</td>
<td>8947027.0</td>
<td>18.22</td>
<td>22.6</td>
<td>3.808</td>
<td>2.142</td>
<td>3823.194</td>
<td>null</td>
<td>561.494</td>
<td>17.65</td>
<td>23.5</td>
<td>48.8</td>
<td>null</td>
<td>null</td>
<td>64.5</td>
<td>0.544</td>
</tr>
<tr class="even">
<td>PNG</td>
<td>Oceania</td>
<td>Papua New Guinea</td>
<td>2020-07-23</td>
<td>31.0</td>
<td>1.0</td>
<td>2.857</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>3.465</td>
<td>0.112</td>
<td>0.319</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>45.37</td>
<td>8947027.0</td>
<td>18.22</td>
<td>22.6</td>
<td>3.808</td>
<td>2.142</td>
<td>3823.194</td>
<td>null</td>
<td>561.494</td>
<td>17.65</td>
<td>23.5</td>
<td>48.8</td>
<td>null</td>
<td>null</td>
<td>64.5</td>
<td>0.544</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_fillNullForSmooth.filter($&quot;iso_code&quot;===&quot;SVK&quot;).sort(&quot;date&quot;).filter($&quot;date&quot;&gt;&quot;2020-03-16&quot; &amp;&amp; $&quot;date&quot;&lt;&quot;2020-03-23&quot;)) // death data correction between 2020-03-18 and 2020-03-22, total_deaths -&gt; all 0, new_deaths -&gt; all 0, new_deaths_smoothed -&gt; all 0
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>iso_code</th>
<th>continent</th>
<th>location</th>
<th>date</th>
<th>total_cases</th>
<th>new_cases</th>
<th>new_cases_smoothed</th>
<th>total_deaths</th>
<th>new_deaths</th>
<th>new_deaths_smoothed</th>
<th>total_cases_per_million</th>
<th>new_cases_per_million</th>
<th>new_cases_smoothed_per_million</th>
<th>total_deaths_per_million</th>
<th>new_deaths_per_million</th>
<th>new_deaths_smoothed_per_million</th>
<th>reproduction_rate</th>
<th>icu_patients</th>
<th>icu_patients_per_million</th>
<th>hosp_patients</th>
<th>hosp_patients_per_million</th>
<th>weekly_icu_admissions</th>
<th>weekly_icu_admissions_per_million</th>
<th>weekly_hosp_admissions</th>
<th>weekly_hosp_admissions_per_million</th>
<th>total_tests</th>
<th>new_tests</th>
<th>total_tests_per_thousand</th>
<th>new_tests_per_thousand</th>
<th>new_tests_smoothed</th>
<th>new_tests_smoothed_per_thousand</th>
<th>tests_per_case</th>
<th>positive_rate</th>
<th>tests_units</th>
<th>stringency_index</th>
<th>population</th>
<th>population_density</th>
<th>median_age</th>
<th>aged_65_older</th>
<th>aged_70_older</th>
<th>gdp_per_capita</th>
<th>extreme_poverty</th>
<th>cardiovasc_death_rate</th>
<th>diabetes_prevalence</th>
<th>female_smokers</th>
<th>male_smokers</th>
<th>handwashing_facilities</th>
<th>hospital_beds_per_thousand</th>
<th>life_expectancy</th>
<th>human_development_index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-17</td>
<td>72.0</td>
<td>9.0</td>
<td>9.286</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>13.188</td>
<td>1.648</td>
<td>1.701</td>
<td>null</td>
<td>0.0</td>
<td>0.0</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>1913.0</td>
<td>318.0</td>
<td>0.35</td>
<td>5.8e-2</td>
<td>173.0</td>
<td>3.2e-2</td>
<td>5.4e-2</td>
<td>18.6</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
<tr class="even">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-18</td>
<td>105.0</td>
<td>33.0</td>
<td>13.571</td>
<td>1.0</td>
<td>1.0</td>
<td>0.143</td>
<td>19.232</td>
<td>6.044</td>
<td>2.486</td>
<td>0.183</td>
<td>0.183</td>
<td>2.6e-2</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>2138.0</td>
<td>225.0</td>
<td>0.392</td>
<td>4.1e-2</td>
<td>192.0</td>
<td>3.5e-2</td>
<td>7.1e-2</td>
<td>14.1</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
<tr class="odd">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-19</td>
<td>123.0</td>
<td>18.0</td>
<td>15.286</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>22.529</td>
<td>3.297</td>
<td>2.8</td>
<td>0.183</td>
<td>0.0</td>
<td>2.6e-2</td>
<td>1.19</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>2439.0</td>
<td>301.0</td>
<td>0.447</td>
<td>5.5e-2</td>
<td>221.0</td>
<td>4.0e-2</td>
<td>6.9e-2</td>
<td>14.5</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
<tr class="even">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-20</td>
<td>137.0</td>
<td>14.0</td>
<td>15.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>25.093</td>
<td>2.564</td>
<td>2.747</td>
<td>0.183</td>
<td>0.0</td>
<td>2.6e-2</td>
<td>1.19</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>2807.0</td>
<td>368.0</td>
<td>0.514</td>
<td>6.7e-2</td>
<td>265.0</td>
<td>4.9e-2</td>
<td>5.7e-2</td>
<td>17.7</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
<tr class="odd">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-21</td>
<td>178.0</td>
<td>41.0</td>
<td>19.143</td>
<td>1.0</td>
<td>0.0</td>
<td>0.143</td>
<td>32.603</td>
<td>7.51</td>
<td>3.506</td>
<td>0.183</td>
<td>0.0</td>
<td>2.6e-2</td>
<td>1.19</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>3247.0</td>
<td>440.0</td>
<td>0.595</td>
<td>8.1e-2</td>
<td>300.0</td>
<td>5.5e-2</td>
<td>6.4e-2</td>
<td>15.7</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
<tr class="even">
<td>SVK</td>
<td>Europe</td>
<td>Slovakia</td>
<td>2020-03-22</td>
<td>185.0</td>
<td>7.0</td>
<td>18.714</td>
<td>null</td>
<td>-1.0</td>
<td>0.0</td>
<td>33.885</td>
<td>1.282</td>
<td>3.428</td>
<td>null</td>
<td>-0.183</td>
<td>0.0</td>
<td>1.18</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>null</td>
<td>3489.0</td>
<td>242.0</td>
<td>0.639</td>
<td>4.4e-2</td>
<td>293.0</td>
<td>5.4e-2</td>
<td>6.4e-2</td>
<td>15.7</td>
<td>null</td>
<td>75.0</td>
<td>5459643.0</td>
<td>113.128</td>
<td>41.2</td>
<td>15.07</td>
<td>9.167</td>
<td>30155.152</td>
<td>0.7</td>
<td>287.959</td>
<td>7.29</td>
<td>23.1</td>
<td>37.7</td>
<td>null</td>
<td>5.82</td>
<td>77.54</td>
<td>0.855</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>Correct new_deaths correction back to 0</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_fillNullForTotalDeathsSpecial = df_fillNullForTotalCases.withColumn(&quot;total_deaths_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;total_deaths&quot;)))
                            .withColumn(&quot;new_deaths_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;new_deaths&quot;)))
                            .withColumn(&quot;new_deaths_smoothed_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;new_deaths_smoothed&quot;)))

</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df_fillNullForTotalDeathsSpecial: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 51 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Expect to see an empty table, so correction is right</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_NULL_total_death_ = df_fillNullForTotalDeathsSpecial.select($&quot;date&quot;,$&quot;iso_code&quot;, $&quot;total_cases&quot;, $&quot;total_deaths_correct&quot;, $&quot;new_cases&quot;, $&quot;new_deaths_correct&quot;, $&quot;new_cases_smoothed&quot;, $&quot;new_deaths_smoothed_correct&quot;)
                          .filter($&quot;total_deaths_correct&quot;.isNull)


df_NULL_total_death_.filter($&quot;total_deaths_correct&quot;.isNull).groupBy(&quot;iso_code&quot;).count().except(df_NULL_total_death_.filter($&quot;new_deaths_correct&quot;===0).groupBy(&quot;iso_code&quot;).count()).show()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>+--------+-----+
|iso_code|count|
+--------+-----+
+--------+-----+

df_NULL_total_death_: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [date: string, iso_code: string ... 6 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>fill rest NULL value for total_death.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_fillNullForTotalDeaths = df_fillNullForTotalDeathsSpecial
                                  .drop(&quot;new_deaths&quot;, &quot;total_deaths&quot;, &quot;new_deaths_smoothed&quot;) // drop old column to rename
                                  .withColumnRenamed(&quot;new_deaths_correct&quot;,&quot;new_deaths&quot;)
                                  .withColumnRenamed(&quot;total_deaths_correct&quot;,&quot;total_deaths&quot;)
                                  .withColumnRenamed(&quot;new_deaths_smoothed_correct&quot;,&quot;new_deaths_smoothed&quot;)
                                  .na.fill(0, Array(&quot;total_deaths&quot;))
                                  .select(df.columns.head, df.columns.tail: _*)
display(df_fillNullForTotalDeaths)
</code></pre>
</div>
<div class="cell markdown">
<h3 id="all-first-10-column-is-clean-now"><a class="header" href="#all-first-10-column-is-clean-now">All first 10 column is clean now!</a></h3>
<p>(All code above is for illustration, for processing just run cell below )</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// filter unknow and HK data
val df_filteredLocation = df.filter($&quot;iso_code&quot;=!=&quot;HKG&quot;).filter($&quot;iso_code&quot;.isNotNull)

// fill missing continent value for World data
val df_fillContinentNull = df_filteredLocation.na.fill(&quot;World&quot;,Array(&quot;continent&quot;)).cache
df_filteredLocation.unpersist()

// filter date before 2020-01-23
val df_filtered_date = df_fillContinentNull.filter($&quot;date&quot;&gt;&quot;2020-01-22&quot;).cache
df_fillContinentNull.unpersist()

// fill missing for new_cases_smoothed and new_deaths_smoothed
val df_fillNullForSmooth = df_filtered_date.na.fill(0,Array(&quot;new_cases_smoothed&quot;))
                           .na.fill(0,Array(&quot;new_deaths_smoothed&quot;))
                           .cache
df_filtered_date.unpersist()

// fill missing for total_cases
val df_fillNullForTotalCases = df_fillNullForSmooth.na.fill(0, Array(&quot;total_cases&quot;)).cache
df_fillNullForSmooth.unpersist()

// correct total_deaths, new_deaths, new_deaths_smoothed
val df_fillNullForTotalDeathsSpecial = df_fillNullForTotalCases.withColumn(&quot;total_deaths_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;total_deaths&quot;)))
                            .withColumn(&quot;new_deaths_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;new_deaths&quot;)))
                            .withColumn(&quot;new_deaths_smoothed_correct&quot;, 
                                        when(col(&quot;iso_code&quot;).equalTo(&quot;ISL&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-13&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-22&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;PNG&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-07-19&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-07-23&quot;),0)
                                       .when(col(&quot;iso_code&quot;).equalTo(&quot;SVK&quot;)&amp;&amp;(col(&quot;date&quot;)&gt;&quot;2020-03-17&quot; &amp;&amp; col(&quot;date&quot;)&lt;&quot;2020-03-23&quot;),0).otherwise(col(&quot;new_deaths_smoothed&quot;)))
                            .cache
df_fillNullForTotalCases.unpersist()

val df_cleaned = df_fillNullForTotalDeathsSpecial
                                  .drop(&quot;new_deaths&quot;, &quot;total_deaths&quot;, &quot;new_deaths_smoothed&quot;) // drop old column to rename
                                  .withColumnRenamed(&quot;new_deaths_correct&quot;,&quot;new_deaths&quot;)
                                  .withColumnRenamed(&quot;total_deaths_correct&quot;,&quot;total_deaths&quot;)
                                  .withColumnRenamed(&quot;new_deaths_smoothed_correct&quot;,&quot;new_deaths_smoothed&quot;)
                                  .na.fill(0, Array(&quot;total_deaths&quot;))
                                  .select(df.columns.head, df.columns.tail: _*)
                                  .cache
df_fillNullForTotalDeathsSpecial.unpersist()

display(df_cleaned)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df_cleaned.columns) {
  println(c + &quot;: &quot; + df_cleaned.filter(col(c).isNull).count())
}
</code></pre>
</div>
<div class="cell markdown">
<h3 id="3-select-invariant-during-pandemic-features-for-clustering"><a class="header" href="#3-select-invariant-during-pandemic-features-for-clustering">3. select invariant (during pandemic) features for clustering</a></h3>
<p>double check whether they are constant for each country, and if not, change all the value to mean and filter out countries that have missing constant features</p>
<p>Candidate list: - population - population<em>density - median</em>age - aged<em>65</em>older - aged<em>70</em>older - gdp<em>per</em>capita</p>
<ul>
<li>cardiovasc<em>death</em>rate</li>
<li>diabetes_prevalence</li>
<li>female_smokers</li>
<li>male_smokers</li>
<li>hospital<em>beds</em>per_thousand</li>
<li>life_expectancy</li>
<li>human<em>development</em>index</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_invariantFeatures = df_cleaned.select($&quot;location&quot;, $&quot;population&quot;,$&quot;population_density&quot;,
                                             $&quot;median_age&quot;, $&quot;aged_65_older&quot;,
                                             $&quot;aged_70_older&quot;,$&quot;gdp_per_capita&quot;,
                                             $&quot;cardiovasc_death_rate&quot;,$&quot;diabetes_prevalence&quot;,
                                             $&quot;female_smokers&quot;,$&quot;male_smokers&quot;,$&quot;hospital_beds_per_thousand&quot;,
                                             $&quot;life_expectancy&quot;,$&quot;human_development_index&quot;)
display(df_invariantFeatures)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_invariantFeatures.describe())
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>summary</th>
<th>location</th>
<th>population</th>
<th>population_density</th>
<th>median_age</th>
<th>aged_65_older</th>
<th>aged_70_older</th>
<th>gdp_per_capita</th>
<th>cardiovasc_death_rate</th>
<th>diabetes_prevalence</th>
<th>female_smokers</th>
<th>male_smokers</th>
<th>hospital_beds_per_thousand</th>
<th>life_expectancy</th>
<th>human_development_index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>count</td>
<td>60104</td>
<td>60104</td>
<td>58524</td>
<td>57260</td>
<td>56312</td>
<td>56944</td>
<td>57260</td>
<td>57892</td>
<td>58524</td>
<td>44928</td>
<td>44296</td>
<td>52835</td>
<td>59788</td>
<td>57576</td>
</tr>
<tr class="even">
<td>mean</td>
<td>null</td>
<td>8.179034692057101E7</td>
<td>305.56040665368073</td>
<td>30.204722319245512</td>
<td>8.595353423781793</td>
<td>5.418455904046091</td>
<td>18397.155660565862</td>
<td>262.00796225730636</td>
<td>7.89011004032537</td>
<td>10.368771011396003</td>
<td>32.645260520137235</td>
<td>3.000101788587119</td>
<td>72.8302766441427</td>
<td>0.7086279005141026</td>
</tr>
<tr class="odd">
<td>stddev</td>
<td>null</td>
<td>5.801702332960505E8</td>
<td>1534.259203474429</td>
<td>9.077112325166668</td>
<td>6.17972101589387</td>
<td>4.214972529727923</td>
<td>19409.896953039588</td>
<td>120.63832428074626</td>
<td>4.2077256136575105</td>
<td>10.396263307877218</td>
<td>13.558764723459655</td>
<td>2.438486660152889</td>
<td>7.538806415792373</td>
<td>0.15398160968293945</td>
</tr>
<tr class="even">
<td>min</td>
<td>Afghanistan</td>
<td>809.0</td>
<td>1.98</td>
<td>15.1</td>
<td>1.144</td>
<td>0.526</td>
<td>661.24</td>
<td>79.37</td>
<td>0.99</td>
<td>0.1</td>
<td>7.7</td>
<td>0.1</td>
<td>53.28</td>
<td>0.354</td>
</tr>
<tr class="odd">
<td>max</td>
<td>Zimbabwe</td>
<td>7.794798729E9</td>
<td>19347.5</td>
<td>48.2</td>
<td>27.049</td>
<td>18.493</td>
<td>116935.6</td>
<td>724.417</td>
<td>30.53</td>
<td>44.0</td>
<td>78.1</td>
<td>13.8</td>
<td>86.75</td>
<td>0.953</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">for (c &lt;- df_invariantFeatures.columns) {
  println(c + &quot;: &quot; + df_invariantFeatures.filter(col(c).isNull).count())
}
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>location: 0
population: 0
population_density: 1580
median_age: 2844
aged_65_older: 3792
aged_70_older: 3160
gdp_per_capita: 2844
cardiovasc_death_rate: 2212
diabetes_prevalence: 1580
female_smokers: 15176
male_smokers: 15808
hospital_beds_per_thousand: 7269
life_expectancy: 316
human_development_index: 2528
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Although some countries seems like an outlier, it does have constant female<em>smokers and male</em>smokers</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val constant_feature_checker = df_cleaned.groupBy(&quot;location&quot;)
          .agg(
              //stddev(&quot;stringency_index&quot;).as(&quot;std_si&quot;),         
              stddev(&quot;population&quot;).as(&quot;std_pop&quot;),           
              stddev(&quot;population_density&quot;).as(&quot;std_pd&quot;),
              stddev(&quot;median_age&quot;).as(&quot;std_ma&quot;),         
              stddev(&quot;aged_65_older&quot;).as(&quot;std_a65&quot;),           
              stddev(&quot;aged_70_older&quot;).as(&quot;std_a70&quot;),  
              stddev(&quot;gdp_per_capita&quot;).as(&quot;std_gdp&quot;),
              stddev(&quot;cardiovasc_death_rate&quot;).as(&quot;std_cdr&quot;),         
              stddev(&quot;diabetes_prevalence&quot;).as(&quot;std_dp&quot;),           
              stddev(&quot;female_smokers&quot;).as(&quot;std_fs&quot;),      
              stddev(&quot;male_smokers&quot;).as(&quot;std_ms&quot;),        
              stddev(&quot;hospital_beds_per_thousand&quot;).as(&quot;std_hbpt&quot;),           
              stddev(&quot;life_expectancy&quot;).as(&quot;std_le&quot;),
              stddev(&quot;human_development_index&quot;).as(&quot;std_hdi&quot;)
            )
           .where(
                  (col(&quot;std_pop&quot;) &gt; 0) || (col(&quot;std_pd&quot;) &gt; 1e-20) || (col(&quot;std_ma&quot;) &gt; 0) || (col(&quot;std_a65&quot;) &gt; 0) || (col(&quot;std_a70&quot;) &gt; 0) || (col(&quot;std_gdp&quot;) &gt; 0 ||
                   col(&quot;std_cdr&quot;) &gt; 0) || (col(&quot;std_dp&quot;) &gt; 0) || (col(&quot;std_fs&quot;) &gt; 0) || (col(&quot;std_ms&quot;) &gt; 0) || (col(&quot;std_hbpt&quot;) &gt; 0) || (col(&quot;std_le&quot;) &gt; 0) || (col(&quot;std_hdi&quot;) &gt; 0))

display(constant_feature_checker)
</code></pre>
</div>
<div class="cell markdown">
<p>Each country have some constant features always</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val distinct_features = df_invariantFeatures.distinct()

display(distinct_features)
</code></pre>
</div>
<div class="cell markdown">
<p>In total, 126 countries have complete features</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val valid_distinct_features = distinct_features.filter($&quot;population&quot;.isNotNull &amp;&amp; $&quot;population_density&quot;.isNotNull &amp;&amp; $&quot;median_age&quot;.isNotNull &amp;&amp; 
                         $&quot;aged_65_older&quot;.isNotNull &amp;&amp; $&quot;aged_70_older&quot;.isNotNull &amp;&amp; $&quot;gdp_per_capita&quot;.isNotNull &amp;&amp;
                         $&quot;cardiovasc_death_rate&quot;.isNotNull &amp;&amp; $&quot;diabetes_prevalence&quot;.isNotNull &amp;&amp; $&quot;female_smokers&quot;.isNotNull &amp;&amp; 
                         $&quot;male_smokers&quot;.isNotNull &amp;&amp; $&quot;hospital_beds_per_thousand&quot;.isNotNull &amp;&amp; $&quot;life_expectancy&quot;.isNotNull &amp;&amp;
                         $&quot;human_development_index&quot;.isNotNull)
display(valid_distinct_features)
</code></pre>
</div>
<div class="cell markdown">
<p>country list</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(valid_distinct_features.select($&quot;location&quot;))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">valid_distinct_features.select($&quot;location&quot;).count()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>res69: Long = 126
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_cleaned_feature = df_cleaned.filter($&quot;location&quot;.isin(valid_distinct_features.select($&quot;location&quot;).rdd.map(r =&gt; r(0)).collect().toSeq: _*))

display(df_cleaned_feature)
</code></pre>
</div>
<div class="cell markdown">
<h3 id="all-data-contains-complete-list-of-invariant-time-feature"><a class="header" href="#all-data-contains-complete-list-of-invariant-time-feature">All data contains complete list of invariant time feature</a></h3>
<p>(All code above is for illustration, for processing just run cell below )</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">// select invariant features
val df_invariantFeatures = df_cleaned.select($&quot;location&quot;, $&quot;population&quot;,$&quot;population_density&quot;,
                                             $&quot;median_age&quot;, $&quot;aged_65_older&quot;,
                                             $&quot;aged_70_older&quot;,$&quot;gdp_per_capita&quot;,
                                             $&quot;cardiovasc_death_rate&quot;,$&quot;diabetes_prevalence&quot;,
                                             $&quot;female_smokers&quot;,$&quot;male_smokers&quot;,$&quot;hospital_beds_per_thousand&quot;,
                                             $&quot;life_expectancy&quot;,$&quot;human_development_index&quot;).cache

// Extract valid distrinct features RDD
val valid_distinct_features = df_invariantFeatures.distinct()
                                 .filter($&quot;population&quot;.isNotNull &amp;&amp; $&quot;population_density&quot;.isNotNull &amp;&amp; $&quot;median_age&quot;.isNotNull &amp;&amp; 
                                 $&quot;aged_65_older&quot;.isNotNull &amp;&amp; $&quot;aged_70_older&quot;.isNotNull &amp;&amp; $&quot;gdp_per_capita&quot;.isNotNull &amp;&amp;
                                 $&quot;cardiovasc_death_rate&quot;.isNotNull &amp;&amp; $&quot;diabetes_prevalence&quot;.isNotNull &amp;&amp; $&quot;female_smokers&quot;.isNotNull &amp;&amp; 
                                 $&quot;male_smokers&quot;.isNotNull &amp;&amp; $&quot;hospital_beds_per_thousand&quot;.isNotNull &amp;&amp; $&quot;life_expectancy&quot;.isNotNull &amp;&amp;
                                 $&quot;human_development_index&quot;.isNotNull).cache

df_invariantFeatures.unpersist()

// filter out NULL feature countries
val df_cleaned_feature = df_cleaned.filter($&quot;location&quot;.isin(valid_distinct_features.select($&quot;location&quot;).rdd.map(r =&gt; r(0)).collect().toSeq: _*)).cache

df_cleaned.unpersist()

display(df_cleaned_feature)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df_cleaned_feature.columns) {
  println(c + &quot;: &quot; + df_cleaned_feature.filter(col(c).isNull).count())
}
</code></pre>
</div>
<div class="cell markdown">
<h3 id="4-imputing-missing-time-series-data-of"><a class="header" href="#4-imputing-missing-time-series-data-of">4. Imputing missing time series data of</a></h3>
<ul>
<li>total<em>cases</em>per_million</li>
<li>new<em>cases</em>per_million</li>
<li>new<em>cases</em>smoothed<em>per</em>million</li>
<li>total<em>deaths</em>per_million</li>
<li>new<em>deaths</em>per_million</li>
<li>new<em>deaths</em>smoothed<em>per</em>million</li>
</ul>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val per_million_data = df_cleaned_feature.select($&quot;location&quot;, $&quot;date&quot;, $&quot;iso_code&quot;, $&quot;total_cases&quot;, 
                                                 $&quot;total_deaths&quot;, $&quot;new_cases&quot;, $&quot;new_deaths&quot;, $&quot;new_cases_smoothed&quot;, 
                                                 $&quot;new_deaths_smoothed&quot;, $&quot;population&quot;, $&quot;population_density&quot;, 
                                                 $&quot;total_cases_per_million&quot;, $&quot;new_cases_per_million&quot;, $&quot;new_cases_smoothed_per_million&quot;, 
                                                 $&quot;total_deaths_per_million&quot;, $&quot;new_deaths_per_million&quot;, $&quot;new_deaths_smoothed_per_million&quot;)

display(per_million_data)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val per_million_data_corrected = per_million_data.withColumn(&quot;total_cases_per_million_correct&quot;, per_million_data(&quot;total_cases&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .withColumn(&quot;new_cases_per_million_correct&quot;, per_million_data(&quot;new_cases&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .withColumn(&quot;new_cases_smoothed_per_million_correct&quot;, per_million_data(&quot;new_cases_smoothed&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .withColumn(&quot;total_deaths_per_million_correct&quot;, per_million_data(&quot;total_deaths&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .withColumn(&quot;new_deaths_per_million_correct&quot;, per_million_data(&quot;new_deaths&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .withColumn(&quot;new_deaths_smoothed_per_million_correct&quot;, per_million_data(&quot;new_deaths_smoothed&quot;)/per_million_data(&quot;population&quot;)*1000000)
                                                 .drop(&quot;total_cases_per_million&quot;, &quot;new_cases_per_million&quot;, &quot;new_cases_smoothed_per_million&quot;, 
                                                       &quot;total_deaths_per_million&quot;, &quot;new_deaths_per_million&quot;, &quot;new_deaths_smoothed_per_million&quot;) // drop old column to rename
                                                 .withColumnRenamed(&quot;total_cases_per_million_correct&quot;,&quot;total_cases_per_million&quot;)
                                                 .withColumnRenamed(&quot;new_cases_per_million_correct&quot;,&quot;new_cases_per_million&quot;)
                                                 .withColumnRenamed(&quot;new_cases_smoothed_per_million_correct&quot;,&quot;new_cases_smoothed_per_million&quot;)
                                                 .withColumnRenamed(&quot;total_deaths_per_million_correct&quot;,&quot;total_deaths_per_million&quot;)
                                                 .withColumnRenamed(&quot;new_deaths_per_million_correct&quot;,&quot;new_deaths_per_million&quot;)
                                                 .withColumnRenamed(&quot;new_deaths_smoothed_per_million_correct&quot;,&quot;new_deaths_smoothed_per_million&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>per_million_data_corrected: org.apache.spark.sql.DataFrame = [location: string, date: string ... 15 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val df_cleaned_feature_permillion = df_cleaned_feature.withColumn(&quot;total_cases_per_million_correct&quot;, df_cleaned_feature(&quot;total_cases&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .withColumn(&quot;new_cases_per_million_correct&quot;, df_cleaned_feature(&quot;new_cases&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .withColumn(&quot;new_cases_smoothed_per_million_correct&quot;, df_cleaned_feature(&quot;new_cases_smoothed&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .withColumn(&quot;total_deaths_per_million_correct&quot;, df_cleaned_feature(&quot;total_deaths&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .withColumn(&quot;new_deaths_per_million_correct&quot;, df_cleaned_feature(&quot;new_deaths&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .withColumn(&quot;new_deaths_smoothed_per_million_correct&quot;, df_cleaned_feature(&quot;new_deaths_smoothed&quot;)/df_cleaned_feature(&quot;population&quot;)*1000000)
                                                   .drop(&quot;total_cases_per_million&quot;, &quot;new_cases_per_million&quot;, &quot;new_cases_smoothed_per_million&quot;, 
                                                         &quot;total_deaths_per_million&quot;, &quot;new_deaths_per_million&quot;, &quot;new_deaths_smoothed_per_million&quot;) // drop old column to rename
                                                   .withColumnRenamed(&quot;total_cases_per_million_correct&quot;,&quot;total_cases_per_million&quot;)
                                                   .withColumnRenamed(&quot;new_cases_per_million_correct&quot;,&quot;new_cases_per_million&quot;)
                                                   .withColumnRenamed(&quot;new_cases_smoothed_per_million_correct&quot;,&quot;new_cases_smoothed_per_million&quot;)
                                                   .withColumnRenamed(&quot;total_deaths_per_million_correct&quot;,&quot;total_deaths_per_million&quot;)
                                                   .withColumnRenamed(&quot;new_deaths_per_million_correct&quot;,&quot;new_deaths_per_million&quot;)
                                                   .withColumnRenamed(&quot;new_deaths_smoothed_per_million_correct&quot;,&quot;new_deaths_smoothed_per_million&quot;)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>df_cleaned_feature_permillion: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 48 more fields]
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="5-impute-time-series-of"><a class="header" href="#5-impute-time-series-of">5. Impute time series of</a></h3>
<ul>
<li>reproduction_rate</li>
<li>total_tests</li>
<li>stringency_index</li>
<li>total<em>tests</em>per_thousand</li>
</ul>
</div>
<div class="cell markdown">
<p>fill null in reproduction_rate by last available and next available value</p>
<p>All countries has missing data at beginning or in the end</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;reproduction_rate&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;reproduction_rate&quot;.isNull).groupBy(&quot;location&quot;).count().sort(&quot;location&quot;))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;reproduction_rate&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;reproduction_rate&quot;.isNull).groupBy(&quot;location&quot;).agg(max(&quot;date&quot;).as(&quot;max_date&quot;), min(&quot;date&quot;).as(&quot;min_date&quot;)).sort(&quot;location&quot;))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;reproduction_rate&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;location&quot;===&quot;Albania&quot;))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

val df_cleaned_reproduction_rate= df_cleaned_feature_permillion.select($&quot;reproduction_rate&quot;, $&quot;location&quot;, $&quot;date&quot;)
                              .withColumn(&quot;reproduction_rate&quot;, last(&quot;reproduction_rate&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
                              .withColumn(&quot;reproduction_rate&quot;, first(&quot;reproduction_rate&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(0, df_cleaned_feature_permillion.count())))
                              .na.fill(0, Array(&quot;reproduction_rate&quot;))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
df_cleaned_reproduction_rate: org.apache.spark.sql.DataFrame = [reproduction_rate: double, location: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>countries miss stringency_index value</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;stringency_index&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;stringency_index&quot;.isNull).groupBy(&quot;location&quot;).count().sort(&quot;count&quot;))
</code></pre>
</div>
<div class="cell markdown">
<p>start and end date for null value of stringency_index for each country</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;stringency_index&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;stringency_index&quot;.isNull).groupBy(&quot;location&quot;).agg(max(&quot;date&quot;).as(&quot;max_date&quot;), min(&quot;date&quot;).as(&quot;min_date&quot;)))
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

val df_cleaned_stringency = df_cleaned_feature_permillion.select($&quot;stringency_index&quot;, $&quot;location&quot;, $&quot;date&quot;)
                              .withColumn(&quot;stringency_index_corect&quot;, last(&quot;stringency_index&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
display(df_cleaned_stringency.filter($&quot;stringency_index&quot;.isNull).filter($&quot;stringency_index_corect&quot;.isNull).groupBy(&quot;location&quot;).count())
</code></pre>
<div class="output execute_result tabular_result" execution_count="1">
<table>
<thead>
<tr class="header">
<th>location</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Comoros</td>
<td>316.0</td>
</tr>
<tr class="even">
<td>Bahamas</td>
<td>316.0</td>
</tr>
<tr class="odd">
<td>Malta</td>
<td>316.0</td>
</tr>
<tr class="even">
<td>Montenegro</td>
<td>316.0</td>
</tr>
<tr class="odd">
<td>Armenia</td>
<td>316.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell markdown">
<p>total_tests, impute by last available or next available value</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

val df_cleaned_total_cases = df_cleaned_feature_permillion.select($&quot;total_tests&quot;, $&quot;location&quot;, $&quot;date&quot;)
                              .withColumn(&quot;total_tests&quot;, last(&quot;total_tests&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
                              .withColumn(&quot;total_tests&quot;, first(&quot;total_tests&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(0, df_cleaned_feature_permillion.count())))
                              .na.fill(0, Array(&quot;total_tests&quot;))
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
df_cleaned_total_cases: org.apache.spark.sql.DataFrame = [total_tests: double, location: string ... 1 more field]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_feature_permillion.select($&quot;total_tests&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;total_tests&quot;.isNull).groupBy(&quot;location&quot;).count())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">val total_tests_date_maxmin = df_cleaned_feature_permillion.select($&quot;total_tests&quot;, $&quot;location&quot;, $&quot;date&quot;).filter($&quot;total_tests&quot;.isNull).groupBy(&quot;location&quot;).agg(max(&quot;date&quot;).as(&quot;max_date&quot;), min(&quot;date&quot;).as(&quot;min_date&quot;))
display(total_tests_date_maxmin)
</code></pre>
</div>
<div class="cell markdown">
<p>process stringency<em>index, reproduction</em>rate, total<em>tests, total</em>tests<em>per</em>thousand</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window

val df_cleaned_time_series = df_cleaned_feature_permillion
                              .withColumn(&quot;reproduction_rate&quot;, last(&quot;reproduction_rate&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
                              .withColumn(&quot;reproduction_rate&quot;, first(&quot;reproduction_rate&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(0, df_cleaned_feature_permillion.count())))
                              .na.fill(0, Array(&quot;reproduction_rate&quot;))
                              .withColumn(&quot;stringency_index&quot;, last(&quot;stringency_index&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
                              .na.fill(0, Array(&quot;stringency_index&quot;))
                              .withColumn(&quot;total_tests&quot;, last(&quot;total_tests&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(-df_cleaned_feature_permillion.count(), 0)))
                              .withColumn(&quot;total_tests&quot;, first(&quot;total_tests&quot;, true)
                                         .over(Window.partitionBy(&quot;location&quot;).orderBy(&quot;date&quot;).rowsBetween(0, df_cleaned_feature_permillion.count())))
                              .na.fill(0, Array(&quot;total_tests&quot;))
                              .withColumn(&quot;total_tests_per_thousand&quot;, col(&quot;total_tests&quot;)/col(&quot;population&quot;)*1000)
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
df_cleaned_time_series: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 48 more fields]
</code></pre>
</div>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">display(df_cleaned_time_series)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-scala">import org.apache.spark.sql.functions._

for (c &lt;- df_cleaned_time_series.columns) {
  println(c + &quot;: &quot; + df_cleaned_time_series.filter(col(c).isNull).count())
}
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/student-project-12_group-CovidPandemic/02_DataPreprocess.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/student-project-12_group-CovidPandemic/02_DataPreprocess.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
