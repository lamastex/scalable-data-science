<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>sds-3.x/ScaDaMaLe</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="contents/student-project-20_group-Generalization/01_Background.html">01_Background</a></li><li class="chapter-item expanded affix "><a href="contents/student-project-20_group-Generalization/02_Random_Forest.html">02_Random_Forest</a></li><li class="chapter-item expanded affix "><a href="contents/student-project-20_group-Generalization/03_CNN_MNIST.html">03_CNN_MNIST</a></li><li class="chapter-item expanded affix "><a href="contents/student-project-20_group-Generalization/04_CNN_Intel_Image.html">04_CNN_Intel_Image</a></li><li class="chapter-item expanded affix "><a href="contents/student-project-20_group-Generalization/05_Horovod_test.html">05_Horovod_test</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h1 id="mixup-and-generalization"><a class="header" href="#mixup-and-generalization">MixUp and Generalization</a></h1>
<p>Group Project Authors:</p>
<ul>
<li>
<p>Olof Zetterqvist</p>
</li>
<li>
<p>Jimmy Aronsson</p>
</li>
<li>
<p>Fredrik Hellstr√∂m</p>
</li>
</ul>
<p>Video: https://chalmersuniversity.box.com/s/ubij9bjekg6lcov13kw16kjhk01uzsmy</p>
</div>
<div class="cell markdown">
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>The goal of supervised machine learning is to predict labels given examples. Specifically, we want to choose some mapping <em>f</em>, referred to as a hypothesis, from a space of examples <em>X</em> to a space of labels <em>Y</em>. As a concrete example, <em>X</em> can be the set of pictures of cats and dogs of a given size, <em>Y</em> can be the set <em>{cat, dog}</em>, and <em>f</em> can be a neural network. To choose <em>f</em>, we rely on a set of labelled data. However, our true goal is to perform well on unseen data, i.e., test data. If an algorithm performs similarly well on unseen data as on the training data we used, we say that it <em>generalizes</em>.</p>
<p>A pertinent question, then, is to explain why a model generalizes and using the answer to improve learning algorithms. For overparameterized deep learning methods, this question has yet to be answered conclusively. Recently, a training procedure called MixUp was proposed to improve the generalization capabilities of neural networks [[1]]. The basic idea is that instead of feeding the raw training data to our supervised learning algorithm, we instead use convex combinations of two randomly selected data points. The benefit of this is two-fold. First, it plays the role of data augmentation: the network will never see two completely identical training samples, since we constantly produce new random combinations. Second, the network is encouraged to behave nicely in-between training samples, which has the potential to reduce overfitting. A connection between performance on MixUp data and generalization abilities of networks trained without the MixUp procedure was also studied in [[2]].</p>
</div>
<div class="cell markdown">
<p>** Project description **</p>
<p>In this project, we will investigate the connection between MixUp and generalization at a large scale by performing a distributed hyperparameter search. We will look at both Random Forests and convolutional neural networks. First, we will the algorithms without MixUp, and study the connection between MixUp performance and test error. Then, we will train the networks on MixUp data, and see whether directly optimizing MixUp performance will yield more beneficial test errors.</p>
<p>To make the hyperparameter search distributed and scalable, we will use the Ray Tune package [[3]]. We also planned to use Horovod to enable the individual networks to handle data in a distributed fashion [[4]]. Scalability would then have entered our project in both the scope of the hyperparameter search and the size of the data set. However, we had unexpected GPU problems and were ultimately forced to skip Horovod due to lack of time.</p>
</div>
<div class="cell markdown">
<p><strong>Summary of findings</strong></p>
<p>Our findings were as follows. For Random Forests, we did not find any significant improvement when using MixUp. This may be due to the fact that Random Forests, since they are not trained iteratively, cannot efficiently utilize MixUp. Furthermore, since Decision Trees are piecewise constant, it is unclear what it would mean to force them to behave nicely in-between training samples. When training a CNN to classify MNIST images, we found practically no difference between training on MixUp data and normal, untouched data. This may be due to MNIST being &quot;too easy&quot;. However, for a CNN trained on CIFAR-10, the benefits of MixUp became noticable. First of all, training the same number of epochs on MixUp data as the normal training data gave a higher accuracy on the validation set. Secondly, while the network started to overfit on normal data, this did not occur to a significant degree when using MixUp data. This indicates that MixUp can be beneficial when the algorithm and data are sufficiently complex.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="random-forests-and-mixup"><a class="header" href="#random-forests-and-mixup">Random Forests and MixUp</a></h2>
<p>First off, we will implement MixUp for a Random Forest applied to the Fashion-MNIST data set. Fashion-MNIST consists of black and white 28x28 images of clothing items [[6]]. We will use the scikit-learn package to implement the Random Forest algorithm, and then perform a distributed hyperparameter search with Ray tune. Thus, scalability enters this part of the project through the hyperparameter search.</p>
<p>First, we will just train the Random Forest using the basic training data and observe the performance. Next, we will do the same but utilizing MixUp. Typically, MixUp is used for iterative algorithms, where a new batch of MixUp data is created at each iteration. However, since a Random Forest is not trained iteratively, we use MixUp to augment our data set by adding a number of MixUp data points to our original data set.</p>
<p>First, we will load the data set.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Loading Fashion-mnist

import tensorflow as tf
(X, y),(testX,testY) = tf.keras.datasets.fashion_mnist.load_data()
X = X.reshape(60000, 28*28)

from sklearn.preprocessing import LabelBinarizer

enc = LabelBinarizer()
y = enc.fit_transform(y)
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we define a function that can be used to generated new MixUp data.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Function to create MixUp data

def create_mixup(X, y, beta_param):
  n = np.shape(X)[0]
  shuffled_indices = np.arange(n).tolist()
  np.random.shuffle(shuffled_indices)
  X_s = X[shuffled_indices]
  y_s = y[shuffled_indices]
  mixup_l = np.random.beta(beta_param,beta_param)
  X_mixed = X*(1-mixup_l) + mixup_l*X_s
  y_mixed = y*(1-mixup_l) + (mixup_l)*(y_s)
  return X_mixed, y_mixed
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we split the data into training and validation sets.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Fixes the issue &quot;AttributeError: 'ConsoleBuffer has no attribute 'fileno'&quot;
import sys
sys.stdout.fileno = lambda: False

import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

# Prepare the data
num_classes = 10
np.random.seed(1)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size=0.5)
X_train_base = X_train.copy()
y_train_base = y_train.copy()
</code></pre>
</div>
<div class="cell markdown">
<p>We now define the training function that will be used by Ray Tune. For each set of hyperparameters, we initialize a Random Forest and train on the data, either with or without added folds of MixUp data. We then evaluate on some metrics of interest.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Fixes the issue &quot;AttributeError: 'ConsoleBuffer has no attribute 'fileno'&quot;
import sys
sys.stdout.fileno = lambda: False

from sklearn import metrics
import numpy as np

from sklearn.ensemble import RandomForestRegressor

def training_function(config, checkpoint_dir=None):
    # Hyperparameters
    n_estimators, max_depth, mixup_folds = config[&quot;n_estimators&quot;], config[&quot;max_depth&quot;], config[&quot;mixup_folds&quot;]
    
    X_train_data = X_train_base.copy()
    y_train_data = y_train_base.copy()
    
    for i in range(mixup_folds):
      X_mixed, y_mixed = create_mixup(X_train_base, y_train_base, 0.2)
      X_train_data = np.concatenate([X_train_data, X_mixed])
      y_train_data = np.concatenate([y_train_data, y_mixed])
    
    # Instantiate model with n_estimators decision trees
    rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, random_state = 1)
    # Train the model on training data
    rf.fit(X_train_data, y_train_data)
    
    &quot;&quot;&quot;
    Logg the results
    &quot;&quot;&quot;
    
    #x_mix, y_mix = mixup_data( x_val, y_val)
    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )
    y_pred_probs = rf.predict(X_test)
    y_pred = np.zeros_like(y_pred_probs)
    y_pred[np.arange(len(y_pred_probs)), y_pred_probs.argmax(1)] = 1
    val_acc = np.mean(np.argmax(y_test,1) == np.argmax(y_pred,1))
    
    y_pred_probs = rf.predict(X_train_base)
    y_pred = np.zeros_like(y_pred_probs)
    y_pred[np.arange(len(y_pred_probs)), y_pred_probs.argmax(1)] = 1
    train_acc = np.mean(np.argmax(y_train_base,1) == np.argmax(y_pred,1))
    
    mean_loss = 1
    
    tune.report(mean_loss=mean_loss, train_accuracy = train_acc, val_accuracy = val_acc)
</code></pre>
</div>
<div class="cell markdown">
<p>Finally, we run the actual hyperparameter search in a distributed fashion. Regarding the amount of MixUp data, we try using no MixUp, or we add 2 folds, effectively tripling the size of the data set.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from ray import tune
from ray.tune import CLIReporter
# Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)

reporter.add_metric_column(&quot;val_accuracy&quot;)
reporter.add_metric_column(&quot;train_accuracy&quot;)



analysis = tune.run(
    training_function,
    config={
      'n_estimators': tune.grid_search([10, 20]),
      'max_depth': tune.grid_search([5, 10]),
      'mixup_folds': tune.grid_search([0, 2])
    },
    local_dir='ray_results',
    progress_reporter=reporter
) 

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;val_accuracy&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell markdown">
<p>Let's look at the data from the different trials to see if we can conclude anything about the efficacy of MixUp.</p>
</div>
<div class="cell code" execution_count="1" scrolled="auto">
<pre><code class="language-python">df[['config.n_estimators', 'config.max_depth', 'config.mixup_folds', 'train_accuracy', 'val_accuracy']]
</code></pre>
<div class="output execute_result html_result" execution_count="1">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>config.n_estimators</th>
      <th>config.max_depth</th>
      <th>config.mixup_folds</th>
      <th>train_accuracy</th>
      <th>val_accuracy</th>
    </tr>
    <tr>
      <th>trial_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7e269_00000</th>
      <td>10</td>
      <td>5</td>
      <td>0</td>
      <td>0.735533</td>
      <td>0.728100</td>
    </tr>
    <tr>
      <th>7e269_00001</th>
      <td>10</td>
      <td>10</td>
      <td>0</td>
      <td>0.887033</td>
      <td>0.835733</td>
    </tr>
    <tr>
      <th>7e269_00002</th>
      <td>10</td>
      <td>5</td>
      <td>2</td>
      <td>0.729433</td>
      <td>0.720333</td>
    </tr>
    <tr>
      <th>7e269_00003</th>
      <td>10</td>
      <td>10</td>
      <td>2</td>
      <td>0.888467</td>
      <td>0.827867</td>
    </tr>
    <tr>
      <th>7e269_00004</th>
      <td>20</td>
      <td>5</td>
      <td>0</td>
      <td>0.734367</td>
      <td>0.729667</td>
    </tr>
    <tr>
      <th>7e269_00005</th>
      <td>20</td>
      <td>10</td>
      <td>0</td>
      <td>0.888367</td>
      <td>0.837833</td>
    </tr>
    <tr>
      <th>7e269_00006</th>
      <td>20</td>
      <td>5</td>
      <td>2</td>
      <td>0.724567</td>
      <td>0.715700</td>
    </tr>
    <tr>
      <th>7e269_00007</th>
      <td>20</td>
      <td>10</td>
      <td>2</td>
      <td>0.865267</td>
      <td>0.818967</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p><strong>Conclusions</strong></p>
<p>Based on the results, MixUp does not seem to help in this context. The validation accuracy achieved with MixUp is actually slightly lower than without it. The reasons for this may be that the data is too simple, that Random Forests cannot fully utilize the power of MixUp augmentation due to not being iterative, or that the piecewise constant nature Decision Trees means that MixUp cannot help too much.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="cnn-for-mnist"><a class="header" href="#cnn-for-mnist">CNN for MNIST</a></h2>
<p>Let us move to a classic machine learning task: Image classification with Convolutional Neural Networks (CNN). The general idea is as follows: 1. Train a CNN on normal training data. Evaluate its performance on a conventional (&quot;unmixed&quot;) validation set and on a MixUp (&quot;mixed&quot;) version of the same validation set. 2. Train a CNN on MixUp training data. Evaluate its performance on both unmixed and mixed validation data.</p>
<p>When training on MixUp training data, we compute a new MixUp of each batch in every epoch. As explained in the introduction, this effectively augments the training set and hopefully makes the network more robust. Evaluating the performance of both networks on unmixed and mixed validation data allows us to compare the generalization properties of both networks, the working hypothesis being that training on MixUp data enhances generalization. To reduce the dependence of our results on the specific choice of hyperparameters, we train several CNNs with varying numbers of convolutional and dense layers. This is done for both kinds of training data (unmixed, mixed) in a distributed fashion using Ray Tune.</p>
<p>In this notebook, we train a simple MNIST classifier. This notebook runs on a CPU, but with a hyperparameter search method that can be scaled up to different workers and be run in parallel.</p>
</div>
<div class="cell markdown">
<p>Import the necessary packages.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout
from ray import tune
from ray.tune import CLIReporter
from sklearn.metrics import confusion_matrix
#from sparkdl import HorovodRunner
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import shutil
import os


# Fixes the issue &quot;AttributeError: 'ConsoleBuffer has no attribute 'fileno'&quot;
import sys
sys.stdout.fileno = lambda: False
</code></pre>
</div>
<div class="cell markdown">
<p>A data generator class that performs MixUp in the loaded data. This is done with two Tensorflow data generators that both load data from our dataset in a shuffled manner and then linearly combined in order to construct the mixed data. The time complexity of this loader is at least twice the time as a normal Tensorflow data loader.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">class MixupImageDataGenerator_from_tensor(tf.keras.utils.Sequence):

    &quot;&quot;&quot;
    A datagenerator that performs mixup on the input data. The input to the generator is numpy arrays with data and labels. 
    &quot;&quot;&quot;
  
    def __init__(self, X,Y, batch_size, alpha=0.2, subset=None):
        self.batch_size = batch_size
        self.batch_index = 0
        self.alpha = alpha
        self.X = X
        self.Y = Y
        
        # First iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(X))
        self.generator1 = iter(tf.data.Dataset.from_tensor_slices((X[ind],Y[ind])).batch(self.batch_size))
        
        
        # Second iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(X))
        self.generator2 = iter(tf.data.Dataset.from_tensor_slices((X[ind],Y[ind])).batch(self.batch_size))

        # Number of images across all classes in image directory.
        self.n = len(X)


    def __len__(self):
        # returns the number of batches
        return (self.n + self.batch_size - 1) // self.batch_size

    def __getitem__(self, index):
        
        if self.batch_index &gt;= self.__len__()-1:
          self.reset_index()
          self.batch_index = 0
        else:
          self.batch_index += 1
        
        # Get a pair of inputs and outputs from two iterators.
        X1, y1 = self.generator1.next()
        X2, y2 = self.generator2.next()
        
        # random sample the lambda value from beta distribution.
        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])

        X_l = l.reshape(X1.shape[0], 1, 1, 1)
        y_l = l.reshape(X1.shape[0], 1)


        # Perform the mixup.
        X = X1 * X_l + X2 * (1 - X_l)
        y = y1 * y_l + y2 * (1 - y_l)
        return X, y

    def reset_index(self):
        &quot;&quot;&quot;Reset the generator indexes array.
        &quot;&quot;&quot;

        # First iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(self.X))
        self.generator1 = iter(tf.data.Dataset.from_tensor_slices((self.X[ind],self.Y[ind])).batch(self.batch_size))
        
        
        # Second iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(self.X))
        self.generator2 = iter(tf.data.Dataset.from_tensor_slices((self.X[ind],self.Y[ind])).batch(self.batch_size))



    def on_epoch_end(self):
        return
        #self.reset_index()
</code></pre>
</div>
<div class="cell markdown">
<p>Two helping methods that create the model based on the hyperparameters &quot;number<em>conv&quot; and &quot;number</em>dense&quot; and create the dataloaders needed for training and validation.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
creates the CNN with number_conv convolutional layers followed by number_dense dense layers. THe model is compiled with a SGD optimizer and a categorical crossentropy loss.
&quot;&quot;&quot;
def create_model(number_conv,number_dense):
    model = Sequential()
    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=&quot;same&quot;, input_shape=(img_height, img_width,channels)))
    model.add(BatchNormalization())
    for s in range(1,number_conv):
        model.add(Conv2D(24+12*s,kernel_size = 3,padding=&quot;same&quot;, activation = 'relu'))
        model.add(BatchNormalization())
    model.add(Flatten())
    model.add(Dropout(0.4))
    for s in range(number_dense):
        model.add(Dense(units=num_classes, activation='relu'))
        model.add(Dropout(0.4))
    model.add(BatchNormalization())
    model.add(Dense(num_classes,activation= &quot;softmax&quot;))
    model.compile(optimizer=&quot;adam&quot;, loss='categorical_crossentropy', metrics=['accuracy'])
    return model


&quot;&quot;&quot;
A method that gives us the different dataloaders that we need for training and validation.

train_mix_loader: A data loader that will give us mixes data for training
train_loader: A data loader that gives us the unmixed training data
val_mixed_loader: A data loader that gives us the mixed validation data
val_loader: A data loader with the unmixed validation data

&quot;&quot;&quot;
        
def get_mnist_dataloaders():
  (trainX,trainY),(testX,testY) = tf.keras.datasets.mnist.load_data()
  trainX,testX = tf.cast(trainX,tf.float32),tf.cast(testX,tf.float32)
  trainX,testX = tf.expand_dims(trainX, 3),tf.expand_dims(testX, 3)
  trainY_oh,testY_oh = tf.one_hot(trainY,10),tf.one_hot(testY,10)
  trainY_oh,testY_oh = tf.cast(trainY_oh,tf.float32).numpy(),tf.cast(testY_oh,tf.float32).numpy()
  trainX,testX = trainX.numpy()/255 * 2 - 2,testX.numpy()/255 * 2 - 2

  
  train_loader_mix = MixupImageDataGenerator_from_tensor(trainX,trainY_oh,batch_size)
  train_loader = tf.data.Dataset.from_tensor_slices((trainX,trainY_oh)).batch(batch_size)
  test_loader_mix = MixupImageDataGenerator_from_tensor(testX,testY_oh,batch_size)
  test_loader = tf.data.Dataset.from_tensor_slices((trainX,trainY_oh)).batch(batch_size)
  
  return train_loader_mix,train_loader,test_loader_mix,test_loader
  
</code></pre>
</div>
<div class="cell markdown">
<p>The method that describes how to construct and train the model.</p>
<p>The steps here are, loading the data and generate the different data loaders, train the model on the preprocessed data and validate the method on the different data sets and report back to the scheduler.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def training_function(config, checkpoint_dir=None):
    # Hyperparameters
    number_conv, number_dense,train_with_mixed_data = config[&quot;number_conv&quot;], config[&quot;number_dense&quot;],config[&quot;train_with_mixed_data&quot;]
    
     
    &quot;&quot;&quot;
    Get the different dataloaders
    One with training data using mixing
    One with training without mixing
    One with validation data with mixing
    One with validation without mixing
    &quot;&quot;&quot;
    #train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(train_dir,test_dir,for_training = True)
    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_mnist_dataloaders()
    &quot;&quot;&quot;
    Construct the model based on hyperparameters
    &quot;&quot;&quot;
    model = create_model( number_conv,number_dense )

    
    &quot;&quot;&quot;
    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?
    &quot;&quot;&quot;
    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=&quot;val_accuracy&quot;,min_delta=0.01,restore_best_weights=True)]

    &quot;&quot;&quot;
    Train the model and give the training history.
    &quot;&quot;&quot;
    if train_with_mixed_data:
      history = model.fit_generator(train_mix_dataloader, validation_data = val_mix_dataloader,callbacks = callbacks,verbose = False,epochs = 200)
    else:
      history = model.fit_generator(train_dataloader, validation_data = val_mix_dataloader,callbacks = callbacks,verbose = False,epochs = 200)
    
    &quot;&quot;&quot;
    Logg the results
    &quot;&quot;&quot;
    #x_mix, y_mix = mixup_data( x_val, y_val)
    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )
    #test_loss, test_acc = model.evaluate( x_val, y_val )
    ind_max = np.argmax(history.history['val_accuracy'])
    train_acc = history.history['accuracy'][ind_max]
    val_acc = history.history['val_accuracy'][ind_max]
    
    tune.report(mean_loss=train_acc,val_mix_accuracy = val_acc)
</code></pre>
</div>
<div class="cell markdown">
<p>The global hyperparameters that we need for training.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">img_height,img_width,channels = 28,28,1
batch_size = 50
alpha = 0.2
num_classes = 10
</code></pre>
</div>
<div class="cell markdown">
<p>The cell that runs the code. In order to train the different models in parallel, we use the ray.tune package that will schedule the training and split the available resources to the various workers.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)
# Add a custom metric column, in addition to the default metrics.
# Note that this must be a metric that is returned in your training results.
reporter.add_metric_column(&quot;val_mix_accuracy&quot;)
#reporter.add_metric_column(&quot;test_accuracy&quot;)

#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}
#training_function(config)

#get_data_loaders()

analysis = tune.run(
    training_function,
    config={
        &quot;number_conv&quot;: tune.grid_search(np.arange(2,5,1).tolist()),
        &quot;number_dense&quot;: tune.grid_search(np.arange(0,3,1).tolist()),
        &quot;train_with_mixed_data&quot;: tune.grid_search([True,False])
    },
    local_dir='ray_results',
    progress_reporter=reporter)

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;mean_loss&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#print(df)
df
</code></pre>
</div>
<div class="cell markdown">
<h4 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h4>
<p>From the dataframe of the results shown above, we can see the accuracy on the validation dataset for the different settings. If we compare the runs with mixup against those without mixup for the different network architectures, we can investigate how much of an effect the mixup implementation has. As we can see, one of the runs did not converge at all. By not including that run, we can see that the average difference off accuracy is 0.01 to the advantage of unmixed data. Without any statistical analysis, we assume this difference is practically zero. Our reasoning to why we don't see any impact of mixup in this simulation is that MNIST is such an easy task to train on that a mixup of the data will not affect the results much.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="cnn-for-intel-image-classification"><a class="header" href="#cnn-for-intel-image-classification">CNN for Intel Image Classification</a></h2>
<p>We will now implement and test the MixUp preprocessing method for a slightly harder CNN example, the Intel Image Classification data set. Again, this notebook runs on CPUs, but the hyperparameter search is scalable.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Imports
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout
from tensorflow.keras import Sequential
from ray import tune
from ray.tune import CLIReporter
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from functools import partial

# Fixes the issue &quot;AttributeError: 'ConsoleBuffer has no attribute 'fileno'&quot;
import sys
sys.stdout.fileno = lambda: False
</code></pre>
</div>
<div class="cell markdown">
<p>We will use the Intel Image Classification data set [[3]]. It consists of 25k 150x150 RBG images from 6 different classes: buildings, forest, glacier, mountain, sea, or street. However when we load the data to our model we will rescale the images to 32x32 RBG images.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
Global parameters for training.
&quot;&quot;&quot;

img_height,img_width,channels = 32,32,3
batch_size = 32
train_data_dir,test_data_dir = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train/&quot;, &quot;dbfs/FileStore/tables/Group20/seg_test/seg_test/&quot;
num_classes = 6
alpha = 0.2 # Degree of mixup is ~ Beta(alpha,alpha)
</code></pre>
</div>
<div class="cell markdown">
<p>To create MixUp data, we will define a custom data generator. It takes an underlying image generator as argument, and outputs convex combinations of two randomly selected (example,label) pairs drawn according to the underlying generator.</p>
<p>Note that, in order to speed up the data generators, we need to make the data more accessible. We do this by copying the data from the dbfs to the working directory. This is done with our copy_data function.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import os, shutil
def copy_data():
  src = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;
  dst = os.path.join(os.getcwd(), 'seg_train')
  print(&quot;Copying data to working folder&quot;)
  shutil.copytree(src, dst)
  print(&quot;Done with copying!&quot;)
  train_data_dir = dst

  src = &quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;
  dst = os.path.join(os.getcwd(), 'seg_test')
  print(&quot;Copying data to working folder&quot;)
  shutil.copytree(src, dst)
  print(&quot;Done with copying!&quot;)
  test_data_dir = dst

  return train_data_dir,test_data_dir
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">class MixupImageDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):
        self.batch_size = batch_size
        self.batch_index = 0
        self.alpha = alpha

        # First iterator yielding tuples of (x, y)
        self.generator1 = generator.flow_from_directory(directory,
                                                        target_size=(
                                                            img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=subset)

        # Second iterator yielding tuples of (x, y)
        self.generator2 = generator.flow_from_directory(directory,
                                                        target_size=(
                                                            img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=subset)

        # Number of images across all classes in image directory.
        self.n = self.generator1.samples


    def __len__(self):
        # returns the number of batches
        return (self.n + self.batch_size - 1) // self.batch_size

    def __getitem__(self, index):
        # Get a pair of inputs and outputs from two iterators.
        X1, y1 = self.generator1.next()
        X2, y2 = self.generator2.next()


        # random sample the lambda value from beta distribution.
        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])

        X_l = l.reshape(X1.shape[0], 1, 1, 1)
        y_l = l.reshape(X1.shape[0], 1)


        # Perform the mixup.
        X = X1 * X_l + X2 * (1 - X_l)
        y = y1 * y_l + y2 * (1 - y_l)
        return X, y

    def reset_index(self):
        &quot;&quot;&quot;Reset the generator indexes array.
        &quot;&quot;&quot;

        self.generator1._set_index_array()
        self.generator2._set_index_array()


    def on_epoch_end(self):
        self.reset_index()
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
A method that gives us the different dataloaders that we need for training and validation.

With for_training set to True, the model gives us the dataloaders
* train_mix_loader: Gives us mixed data for training
* train_loader:     Gives us the unmixed training data
* val_mix_loader:   Gives us mixed validation data
* val_loader:       Gives us unmixed validation data

By setting for_training to False, the method gives us the dataloader
* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.
&quot;&quot;&quot;
def get_data_loaders(train_data_dir,test_data_dir,for_training = True):
  
    #For training data
    if for_training:
        datagen_train_val = ImageDataGenerator(rescale=1./255,
                                rotation_range=5,
                                width_shift_range=0.05,
                                height_shift_range=0,
                                shear_range=0.05,
                                zoom_range=0,
                                brightness_range=(1, 1.3),
                                horizontal_flip=True,
                                fill_mode='nearest',
                                validation_split=0.1)

        train_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,
                                                   directory = train_data_dir,
                                                   batch_size = batch_size,
                                                   img_height = img_height,
                                                   img_width = img_width,
                                                   alpha=alpha,
                                                   subset=&quot;training&quot;)
        
        val_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,
                                                 directory = train_data_dir,
                                                 batch_size = batch_size,
                                                 img_height = img_height,
                                                 img_width = img_width,
                                                 alpha=alpha,
                                                 subset=&quot;validation&quot;)

        train_loader = datagen_train_val.flow_from_directory(train_data_dir,
                                                        target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=&quot;training&quot;)

        val_loader = datagen_train_val.flow_from_directory(train_data_dir,
                                                        target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=&quot;validation&quot;)
        
        return train_mix_loader,train_loader, val_mix_loader, val_loader

    #For test data
    else:
        datagen_test = ImageDataGenerator(rescale=1./255,
                                rotation_range=0,
                                width_shift_range=0,
                                height_shift_range=0,
                                shear_range=0,
                                zoom_range=0,
                                brightness_range=(1, 1),
                                horizontal_flip=False,
                                fill_mode='nearest',
                                validation_split=0)

        test_loader = datagen_test.flow_from_directory(test_data_dir,
                                                    target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=False,
                                                        subset=None)

        return test_loader
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we define the function for creating the CNN.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
creates the CNN with number_conv convolutional layers followed by number_dense dense layers. The model is compiled with a SGD optimizer and a categorical crossentropy loss.
&quot;&quot;&quot;
def create_model(number_conv,number_dense):
    model = Sequential()
    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=&quot;same&quot;, input_shape=(img_height, img_width,channels)))
    model.add(BatchNormalization())
    for s in range(1,number_conv):
        model.add(Conv2D(24+12*s,kernel_size = 3,padding=&quot;same&quot;, activation = 'relu'))
        model.add(BatchNormalization())
    model.add(Flatten())
    model.add(Dropout(0.4))
    for s in range(number_dense):
        model.add(Dense(units=num_classes, activation='relu'))
        model.add(Dropout(0.4))
    model.add(BatchNormalization())
    model.add(Dense(num_classes,activation= &quot;softmax&quot;))
    model.compile(optimizer=&quot;adam&quot;, loss='categorical_crossentropy', metrics=['accuracy'])
    return model
</code></pre>
</div>
<div class="cell markdown">
<p>This is the function that the ray.tune method will run. The steps in the function is to generate the dataloaders that will load the data from the working dictionary, create the model based on the hyperparameters given in the config dictionary, train the model and evaluate the model on the different datasets.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def training_function(config, checkpoint_dir=None):
    # Hyperparameters
    number_conv, number_dense = config[&quot;number_conv&quot;], config[&quot;number_dense&quot;]
    train_with_mixed_data = config[&quot;train_with_mixed_data&quot;]
    
    
    &quot;&quot;&quot;
    Get the different dataloaders
    One with training data using mixing
    One with training without mixing
    One with validation data with mixing
    One with validation without mixing
    Set for_training to False to get testing data
    &quot;&quot;&quot;
    #train_data_dir,test_data_dir = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;,&quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;

    #train_data_dir, test_data_dir = copy_data()
    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(train_data_dir, test_data_dir, for_training = True)

    &quot;&quot;&quot;
    Construct the model based on hyperparameters
    &quot;&quot;&quot;
    model = create_model( number_conv,number_dense )

    
    &quot;&quot;&quot;
    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?
    &quot;&quot;&quot;
    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=&quot;val_accuracy&quot;,min_delta=0.01,restore_best_weights=True)]

    &quot;&quot;&quot;
    Train the model and give the training history.
    &quot;&quot;&quot;
    if train_with_mixed_data:
      history = model.fit_generator(train_mix_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)
    else:
      history = model.fit_generator(train_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)
    
    &quot;&quot;&quot;
    Logg the results
    &quot;&quot;&quot;
    #x_mix, y_mix = mixup_data( x_val, y_val)
    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )
    train_loss_unmix, train_acc_unmix = model.evaluate( train_dataloader )
    val_mix_loss, val_mix_acc = model.evaluate( val_mix_dataloader )
    ind_max = np.argmax(history.history['val_accuracy'])
    train_mix_acc = history.history['accuracy'][ind_max]
    train_mix_loss = history.history[&quot;loss&quot;][ind_max]
    train_loss = history.history['loss'][ind_max]
    val_acc = history.history['val_accuracy'][ind_max]
    val_loss = history.history['val_loss'][ind_max]
    
    tune.report(mean_loss=train_mix_loss, train_mix_accuracy = train_mix_acc, train_accuracy = train_acc_unmix, val_mix_accuracy = val_mix_acc, val_accuracy = val_acc)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">train_data_dir,test_data_dir = copy_data()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Copying data/files to local horovod folder...
Done with copying!
Copying data/files to local horovod folder...
Done with copying!
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>First, we will train our neural networks using a standard procedure, with normal training data. We then measure their performance on a validation set as well as on a MixUp version of the same validation set, the idea being to study the connection between these metrics.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)
# Add a custom metric column, in addition to the default metrics.
# Note that this must be a metric that is returned in your training results.
reporter.add_metric_column(&quot;val_mix_accuracy&quot;)
reporter.add_metric_column(&quot;val_accuracy&quot;)
reporter.add_metric_column(&quot;train_accuracy&quot;)
reporter.add_metric_column(&quot;train_mix_accuracy&quot;)

#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}
#training_function(config)

#get_data_loaders()

analysis = tune.run(
    training_function,
    config={
        &quot;number_conv&quot;: tune.grid_search(np.arange(2,7,3).tolist()),
        &quot;number_dense&quot;: tune.grid_search(np.arange(0,3,2).tolist()),
        &quot;train_with_mixed_data&quot;: False
    },
    local_dir='ray_results',
    progress_reporter=reporter
) 
  #resources_per_trial={'gpu': 1})

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;val_accuracy&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">df
</code></pre>
</div>
<div class="cell markdown">
<p>We now check whether directly training on MixUp data has a positive effect on network performance.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)
# Add a custom metric column, in addition to the default metrics.
# Note that this must be a metric that is returned in your training results.
reporter.add_metric_column(&quot;val_mix_accuracy&quot;)
reporter.add_metric_column(&quot;val_accuracy&quot;)
reporter.add_metric_column(&quot;train_accuracy&quot;)

#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}
#training_function(config)

#get_data_loaders()

analysis = tune.run(
    training_function,
    config={
        &quot;number_conv&quot;: tune.grid_search(np.arange(2,7,3).tolist()),
        &quot;number_dense&quot;: tune.grid_search(np.arange(0,3,2).tolist()),
        &quot;train_with_mixed_data&quot;: True
    },
    local_dir='ray_results',
    progress_reporter=reporter)
    
  #resources_per_trial={'gpu': 1})

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;val_accuracy&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">df
</code></pre>
</div>
<div class="cell markdown">
<p><strong>Conclusions</strong></p>
<p>We found that training a CNN using the Ray package was harder than we thought from the beginning. This is probably due to the GPU usage and that we had problems assigning the Keras model to the correct GPU. In other words, Ray requested GPU usage but the code only ever ran on CPU, which took an unfeasible amount of time.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
</div>
<div style="break-before: page; page-break-before: always;"></div><div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="cnns-and-mixup-with-horovod"><a class="header" href="#cnns-and-mixup-with-horovod">CNNs and MixUp with Horovod</a></h2>
<p>One of the arguments in favor for using MixUp is the data augmentation it provides. For iterative learning algorithms, such as CNNs trained with a variant of stochastic gradient descent, we can generate new MixUp data for each training batch. This effectively means that the network will never see any training example twice. To harness this positive aspect of MixUp to its fullest extent, we want our algorithm to be scalable in the data to use it efficiently. To train neural networks in a scalable way with respet to the data, one can use Horovod, which parallelizes the neural network training procedure.</p>
<p>In this notebook, we use Horovod to train a CNN on the CIFAR-10 data set, both without and with MixUp. While the notebook is executed with only one GPU, the code scales nicely if more GPUs are available.</p>
</div>
<div class="cell markdown">
<p>First, we import packages and check what computational resources are available. In this case, we have one GPU.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import horovod.tensorflow.keras as hvd
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout
from tensorflow.keras import Sequential
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from functools import partial
import os
import time

print(tf.__version__)
from tensorflow.python.client import device_lib
local_device_protos = device_lib.list_local_devices()
print(local_device_protos)

checkpoint_dir = '/dbfs/ml/Group_20/train/{}/'.format(time.time())

os.makedirs(checkpoint_dir)
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we define the generator for our MixUp images.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">class MixupImageDataGenerator_from_tensor(tf.keras.utils.Sequence):

    &quot;&quot;&quot;
    A datagenerator that performs mixup on the input data. The input to the generator is numpy arrays with data and labels. 
    &quot;&quot;&quot;
  
    def __init__(self, X,Y, batch_size, alpha=0.2, subset=None):
        self.batch_size = batch_size
        self.batch_index = 0
        self.alpha = alpha
        self.X = X
        self.Y = Y
        
        # First iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(X))
        self.generator1 = iter(tf.data.Dataset.from_tensor_slices((X[ind],Y[ind])).batch(self.batch_size))
        
        
        # Second iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(X))
        self.generator2 = iter(tf.data.Dataset.from_tensor_slices((X[ind],Y[ind])).batch(self.batch_size))

        # Number of images across all classes in image directory.
        self.n = len(X)


    def __len__(self):
        # returns the number of batches
        return (self.n + self.batch_size - 1) // self.batch_size

    def __getitem__(self, index):
        
        if self.batch_index &gt;= self.__len__()-1:
          self.reset_index()
          self.batch_index = 0
        else:
          self.batch_index += 1
        
        # Get a pair of inputs and outputs from two iterators.
        X1, y1 = self.generator1.next()
        X2, y2 = self.generator2.next()
        
        # random sample the lambda value from beta distribution.
        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])

        X_l = l.reshape(X1.shape[0], 1, 1, 1)
        y_l = l.reshape(X1.shape[0], 1)


        # Perform the mixup.
        X = X1 * X_l + X2 * (1 - X_l)
        y = y1 * y_l + y2 * (1 - y_l)
        return X, y

    def reset_index(self):
        &quot;&quot;&quot;Reset the generator indexes array.
        &quot;&quot;&quot;

        # First iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(self.X))
        self.generator1 = iter(tf.data.Dataset.from_tensor_slices((self.X[ind],self.Y[ind])).batch(self.batch_size))
        
        
        # Second iterator yielding tuples of (x, y)
        ind = np.random.permutation(len(self.X))
        self.generator2 = iter(tf.data.Dataset.from_tensor_slices((self.X[ind],self.Y[ind])).batch(self.batch_size))



    def on_epoch_end(self):
        return
        #self.reset_index()
        
        
</code></pre>
</div>
<div class="cell markdown">
<p>We now define functions for creating the neural network and initializing the dataloaders. We will use dataloaders both with and without MixUp for both training and validation.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
creates the CNN with number_conv convolutional layers followed by number_dense dense layers. THe model is compiled with a SGD optimizer and a categorical crossentropy loss.
&quot;&quot;&quot;
def create_model(number_conv,number_dense,optimizer = &quot;adam&quot;):
    model = Sequential()
    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=&quot;same&quot;, input_shape=(img_height, img_width,channels)))
    model.add(BatchNormalization())
    for s in range(1,number_conv):
        model.add(Conv2D(24+12*s,kernel_size = 3,padding=&quot;same&quot;, activation = 'relu'))
        model.add(BatchNormalization())
    model.add(Flatten())
    model.add(Dropout(0.4))
    for s in range(number_dense):
        model.add(Dense(units=num_classes, activation='relu'))
        model.add(Dropout(0.4))
    model.add(BatchNormalization())
    model.add(Dense(num_classes,activation= &quot;softmax&quot;))
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model


&quot;&quot;&quot;
A method that gives us the different dataloaders that we need for training and validation. with for_training set to True the model will give us the dataloades

train_mix_loader: A data loader that will give us mixes data for training
train_loader: A data loader that gives us the unmixed training data
val_mixed_loader: A data loader that gives us the mixed validation data
val_loader: A data loader with the unmixed validation data

By setting for_training to False the method will give us the dataloader

test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.
&quot;&quot;&quot;
def get_cifar_dataloaders():
    (trainX,trainY),(testX,testY) = tf.keras.datasets.cifar10.load_data()
    trainX,testX = tf.cast(trainX,tf.float32),tf.cast(testX,tf.float32)
    #trainX,testX = tf.expand_dims(trainX, 3),tf.expand_dims(testX, 3)
    trainY_oh,testY_oh = tf.one_hot(trainY[:,0],10),tf.one_hot(testY[:,0],10)
    trainY_oh,testY_oh = tf.cast(trainY_oh,tf.float32).numpy(),tf.cast(testY_oh,tf.float32).numpy()
    trainX,testX = trainX.numpy()/255 * 2 - 2,testX.numpy()/255 * 2 - 2


    train_loader_mix = MixupImageDataGenerator_from_tensor(trainX,trainY_oh,batch_size)
    train_loader = tf.data.Dataset.from_tensor_slices((trainX,trainY_oh)).batch(batch_size)
    test_loader_mix = MixupImageDataGenerator_from_tensor(testX,testY_oh,batch_size)
    test_loader = tf.data.Dataset.from_tensor_slices((trainX,trainY_oh)).batch(batch_size)

    return train_loader_mix,train_loader,test_loader_mix,test_loader
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we define the training function that will be used by Horovod. Each worker uses the datagenerator to load data.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def train_hvd(learning_rate=1.0, train_with_mix = False):
  # Import tensorflow modules to each worker
  from tensorflow.keras import backend as K
  from tensorflow.keras.models import Sequential
  import tensorflow as tf
  from tensorflow import keras
  import horovod.tensorflow.keras as hvd
  
  # Initialize Horovod
  hvd.init()

  # Pin GPU to be used to process local rank (one GPU per process)
  # These steps are skipped on a CPU cluster
  gpus = tf.config.experimental.list_physical_devices('GPU')
  for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
  if gpus:
    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')

  # Call the get_dataset function you created, this time with the Horovod rank and size
  train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_cifar_dataloaders()
  model = create_model( number_conv,number_dense )

  # Adjust learning rate based on number of GPUs
  optimizer = keras.optimizers.Adadelta(lr=learning_rate * hvd.size())

  # Use the Horovod Distributed Optimizer
  optimizer = hvd.DistributedOptimizer(optimizer)

  model.compile(optimizer=optimizer,
                loss='categorical_crossentropy',
                metrics=['accuracy'])

  # Create a callback to broadcast the initial variable states from rank 0 to all other processes.
  # This is required to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.
  callbacks = [
      hvd.callbacks.BroadcastGlobalVariablesCallback(0),
  ]

  # Save checkpoints only on worker 0 to prevent conflicts between workers
  if hvd.rank() == 0:
      callbacks.append(keras.callbacks.ModelCheckpoint(checkpoint_dir + '/checkpoint-{epoch}.ckpt', save_weights_only = True))
      
  if train_with_mix:
    model.fit(train_mix_dataloader,
            batch_size=batch_size,
            callbacks=callbacks,
            epochs=epochs,
            verbose=2,
            validation_data=val_dataloader)
  else:
    model.fit(train_dataloader,
            batch_size=batch_size,
            callbacks=callbacks,
            epochs=epochs,
            verbose=2,
            validation_data=val_dataloader)
       
</code></pre>
</div>
<div class="cell markdown">
<p>Below, we give the parameters that control the training procedure.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
The global parameters for training.
&quot;&quot;&quot;

img_height,img_width,channels = 32,32,3
batch_size = 32
#train_data_dir,test_data_dir = &quot;/content/seg_train/seg_train&quot;,&quot;/content/seg_test/seg_test&quot;
#train_data_dir,test_data_dir = &quot;dbfs/FileStore/tables/Group20/seg_train/seg_train/&quot;, &quot;dbfs/FileStore/tables/Group20/seg_test/seg_test/&quot;
#train_data_dir,test_data_dir = copy_data()
num_classes = 10
number_conv = 4
number_dense = 2
epochs = 30
alpha = 0.2
#train_with_mixed_data = True
</code></pre>
</div>
<div class="cell markdown">
<p>Now, let us run training with Horovod, first on MixUp data, then without MixUp.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from sparkdl import HorovodRunner

hr = HorovodRunner(np=2)
hr.run(train_hvd, learning_rate=0.1, train_with_mix = True)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">from sparkdl import HorovodRunner

hr_nomix = HorovodRunner(np=2)
hr_nomix.run(train_hvd, learning_rate=0.1, train_with_mix = False)
</code></pre>
</div>
<div class="cell markdown">
<h4 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h4>
<p>From our simulations on CIFAR-10 with and without MixUp it seems that MixUp provides stability against overfitting and has a bit higher top validation accuracy during training. Specifically, when using MixUp, we reach a validation accuracy around 75%, while we peak at 70% without MixUp. Furthermore, when not using MixUp, the validation accuracy starts to decrease after 20 epochs, while it continues to improve with MixUp. Since this is based on only one simulation, we cannot be fully certain about these conclusions. When it comes to the scalability of the model, Horovod provides beneficial scaling with the data and makes the code very simular to a regular single-machine training notebook. Horovod can also be combined with Ray Tune to also perform a hyperparameter search, but this was not done in this project.</p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </body>
</html>
